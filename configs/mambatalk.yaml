is_train: True
ddp: False
stat: ts
root_path: ./
out_path: ./outputs/audio2pose/
project: s2g
data_path: ./data/
e_path: weights/AESKConv_240_100.bin
eval_model: motion_representation
e_name: null
test_ckpt: ./outputs/audio2pose/custom/0221_064211_mambatalk/last_90.bin
data_path_1: ./pretrained/
vae_test_len: 32
vae_test_dim: 320
vae_test_stride: 20
vae_length: 240
vae_codebook_size: 256
vae_layer: 4
vae_grow: [1,1,2,1]
variational: False

# data config
training_speakers: [1]
additional_data: False
cache_path: datasets/beat_cache/mhr_mambatalk/
dataset: beat_sep_lower
new_cache: False

# motion config (MHR native)
ori_joints: beat_smplx_joints
tar_joints: beat_smplx_full
pose_rep: smplxflame_30
pose_norm: False
pose_fps: 30
rot6d: False
pre_frames: 4
# pose_dims = body(130) + hand(108) + face(75) + global(7) = 320
# global = global_rot(3) + contact(4); cam_t is sequence-level constant
pose_dims: 320
pose_length: 64
stride: 20
test_length: 64
motion_f: 256
m_pre_encoder: null
m_encoder: null
m_fix_pre: False

# MHR part dimensions
face_dims: 75
body_dims: 130
hand_dims: 108
global_dims: 7

# audio config
audio_rep: amplitude+ctc+audio
audio_sr: 16000
audio_fps: 16000
audio_norm: False
audio_f: 512

# text config
word_rep: textgrid
word_index_num: 11195
word_dims: 300
freeze_wordembed: False
word_f: 256
t_pre_encoder: fasttext
t_encoder: null
t_fix_pre: False

# facial config
facial_rep: smplxflame_30
facial_dims: 75
facial_norm: False
facial_f: 0
f_pre_encoder: null
f_encoder: null
f_fix_pre: False

# speaker config
id_rep: onehot
speaker_f: 0

# model config
batch_size: 64
lr_base: 5e-4
model: mambatalk
g_name: MambaTalk
trainer: mambatalk
hidden_size: 768
n_layer: 1

rec_weight: 1
grad_norm: 0.99
epochs: 200
test_period: 10
test_start_epoch: 70
ll: 3
lf: 3
lu: 3
lh: 3
cl: 1
cf: 0
cu: 1
ch: 2
vel_global_weight: 2.0
vel_body_weight: 0.5
vel_hands_weight: 1.0
acc_body_weight: 1.0
acc_global_weight: 1.0
acc_hands_weight: 0.5
pose_body_weight: 1.0
pose_vel_body_weight: 1.0
